{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6eede9-775b-421b-8185-54998b49deec",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "With huge number of images to be loaded and processed, we will not have enough RAM to load and process all the images at once. The solution is not to read the data until it is required, load and process the images in batches as and when required by the model. The pre processing also has to be done on the fly in batches as part of the model. In keras this job is done by image data generator. Give the fit method the generator instead of the data array(x_train, y_train) directly, it takes care of loading and unloading the images in batches. Image data generator is implemented using python generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f1f43c-fbd8-45ae-b7c4-33d57fde2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2, os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a97eb6-bf4d-45a9-ba6f-f78ccf9fc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data generator needs the data to be organised in a specific folder structure\n",
    "# It needs a root folder and in it one folder for each category\n",
    "# The category folders should have their repective category images\n",
    "os.mkdir(\"master_data\")\n",
    "os.mkdir(\"master_data/cat\")\n",
    "os.mkdir(\"master_data/dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e01a30-cfb4-405a-b9f3-4f5784a7927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the images into the folder structure based on their category\n",
    "src = \"train/\"\n",
    "dst_cat = \"master_data/cat/\"\n",
    "dst_dog = \"master_data/dog/\"\n",
    "\n",
    "for file_name in os.listdir(src):\n",
    "    if \"dog\" in file_name:\n",
    "        shutil.copy(src+file_name, dst_dog)\n",
    "    else:\n",
    "        shutil.copy(src+file_name, dst_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023e58e6-a34d-498a-a11a-0c93b3ec317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(dst_dog)))\n",
    "print(len(os.listdir(dst_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce3c18c-fbed-4ec4-a04c-86d33ba78b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "idg = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1, rescale=1/255.0)\n",
    "# one hot encoding is done by the generator itself\n",
    "train_idg = idg.flow_from_directory(directory=\"master_data\", target_size=(150,150), batch_size=batch_size, \n",
    "                                    subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90da1397-c324-4d7b-a03d-f4751e9b6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = idg.flow_from_directory(directory=\"master_data\", target_size=(150,150), batch_size=batch_size, \n",
    "                                  subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7aa78c-b755-4398-8803-cdb881fcff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Flatten (Flatten)           (None, 67500)             0         \n",
      "                                                                 \n",
      " Hidden (Dense)              (None, 128)               8640128   \n",
      "                                                                 \n",
      " Output (Dense)              (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,640,386\n",
      "Trainable params: 8,640,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input((150,150,3), name=\"Input\"))\n",
    "model.add(tf.keras.layers.Flatten(name=\"Flatten\"))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.keras.activations.relu, name=\"Hidden\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax, name=\"Output\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f9b005-d307-4308-9c71-1589775315ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.categorical_crossentropy, metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6fa4f4e-6bf1-4a04-84b9-e38fe2dc9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 78s 110ms/step - loss: 0.6999 - acc: 0.5627 - val_loss: 0.6908 - val_acc: 0.5624\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 76s 108ms/step - loss: 0.6577 - acc: 0.6092 - val_loss: 0.6626 - val_acc: 0.6008\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 76s 108ms/step - loss: 0.6477 - acc: 0.6202 - val_loss: 0.6500 - val_acc: 0.6192\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 76s 108ms/step - loss: 0.6401 - acc: 0.6284 - val_loss: 0.6524 - val_acc: 0.6136\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 75s 107ms/step - loss: 0.6320 - acc: 0.6380 - val_loss: 0.6355 - val_acc: 0.6272\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 74s 106ms/step - loss: 0.6267 - acc: 0.6451 - val_loss: 0.6461 - val_acc: 0.6308\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 75s 106ms/step - loss: 0.6202 - acc: 0.6540 - val_loss: 0.6401 - val_acc: 0.6188\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 76s 108ms/step - loss: 0.6170 - acc: 0.6516 - val_loss: 0.6525 - val_acc: 0.6284\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 75s 107ms/step - loss: 0.6119 - acc: 0.6603 - val_loss: 0.6322 - val_acc: 0.6320\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 77s 109ms/step - loss: 0.6072 - acc: 0.6688 - val_loss: 0.6316 - val_acc: 0.6416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258c96a79a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_idg, batch_size=batch_size, epochs=10, validation_data=val_idg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
