{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fb9cdc",
   "metadata": {},
   "source": [
    "Given a sequence of n numbers in which the numbers are not in any particular order, the sorting algorithm should reorder the numbers in increasing order. Sorting can be applied to numbers, characters, strings or any objects that can be compared against each other. Some of the applications of sorting are searching is faster in sorted array, find duplicate elements easily using sorting, matching up items from 2 or more files, can easily find median of the given data and top list of items that are relavent(search results, news feeds, tweets etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397330d",
   "metadata": {},
   "source": [
    "## Design Strategies\n",
    "* Brute Force : The most straightforward approach, usually based on the problem statement. Read the problem, understand it, think about it and a straightforward algorithm might come to your mind. So it depends on the individual trying to solve the problem. Normally this approach will be exhaustive, try all elements, try every combination for the given problem. For sorting, this means trying all the combinations of the elements and picking the sorted combination.\n",
    "* Decrease and Conquer : Decrease the given problem of size n to size n - 1 by solving for 1 element, i.e try to make the problem slightly smaller. We continue to decrease the sub smaller problem repeatedly, untill all the elements are done, this is recursive thinking. There are 2 ways to do this. \n",
    "    * Upfront work to solve for one more element : Solve for one element in one iteration, then continue. In the case of sorting this is to get the smallest element to the first location, thus reducing the remaining problem to n - 1 elements and repeating this. Selection sort and bubble sort use this algorithm.\n",
    "    * Work at the end to extend for one more element : First n - 1 elements have already been solved, now extend this to the nth element. In the case of sorting this means the first n -1 elements have already been sorted, now we have to place the nth element in the correct sorted position(in the nth iteration). Insertion sort uses this algorithm.\n",
    "* Divide and Conquer : Divide the problem into multiple smaller problems(most often 2), generally of the same size. Solve the smaller problems, typically using recursion. Then combine the solutions of the smaller problems to get the solution of the original porblem. For the sorting problem, we have to combine 2 smaller sorted arrays to get the combined sorted array. One way to do this is to compare the elements in the 2 sorted arrays and fill up a temporary auxiliary array(of combined array size) in a sorted order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb85f47",
   "metadata": {},
   "source": [
    "## Asymptotic Analysis\n",
    "How do we measure the running time of an algorithm. We can code up the algorithm, run it on a machine and measure how much time it takes to run. But this value would be different for different machines, different for different programming languages, depends on what is running on the operating system and different for different inputs. Asymptotic analysis deals with system independent factors.\n",
    "* Input size is a system independent factor, for example a larger array will take longer time to sort. So we define running time as function of input size, T(n), where n is the input size, so we compute T(n) in terms of n. For a input of size n we measure the running time of the algorithm as the number of basic operations in the pseudocode/code. A basic operation is any operation in high level language with a fixed execution time. Examples are variable assignment, simple arithmetic operation, full conditional statement, etc. All of these opearions may not take the same time, but each operation takes a constant time in a given machine, hence we give them cost values, C1, C2, C3, etc.\n",
    "* For many algorithms, for the same input size n, T(n) can take a variety of values depending on data(nature of input). Therefore we talk about best case, worst case and average case times for these algorithms. The worst case is the most important metric as we are dealing with worst possible input data for the algorithm, thus will work better for all other inputs.\n",
    "* Recurrence equation is mathematical way to determine running time T(n). For a selection sort the first equation will be T(n) = n(complexity to sort the first element) + T(n-1), after sorting the second element this will become T(n) = n + (n-1) + T(n-2), on expanding the full equation this will become T(n) = n + (n-1) + (n-2) + ... + 1, that is θ(n<sup>2</sup>). This can be applied to any algorithm, for worst and best cases too. Similarly for merge sort the first equation would be T(n) = n(merge the 2 sorted arrays at the top level) + 2 * T(n/2), after the second level this will be T(n) = n + n + 4 * T(n/4), on expanding the full equation this will be T(n) = n + n + ... + n(logn times), that is θ(nlogn).\n",
    "* The worst case running time is an upper bound on the running time for any input of size n. It is also called Big O(notation) time. For insertion sort worst case is θ(n<sup>2</sup>), which is notated as O(n<sup>2</sup>). This new notation is needed because for complicated algorithms, representing worst case times in θ will be a complicated equation, so we do a second level of approximation to Big O notation, this should be the upper bound of the complicated equation. As the worst case is the most important metric, we normally speak of Big O for running times of algorithms.\n",
    "* A similar type of approximation can be done for best case times, this should be the lower bound of the complicated equation, this is known as Big-Omega notation. For insertion sort best case is θ(n), which is notated as Ω(n).Not an important metric for algorithms.\n",
    "* An algorithm that runs in θ(1) is a constant time algorithm, θ(logn) is a logarithmic time algorithm, θ(n) is a linear time algorithm, θ(nlogn) is a lineararithmic time algorithm, O(n<sup>2</sup>) is a quadratic time algorithm, O(n<sup>3</sup>) is a cubic time algorithm and O(2<sup>n</sup>) is a exponential time algorithm. Untill θ(nlogn) time compplexity input sizes in millons can be processed in a resonable amount of time, beyoud that processing times become unreasonable.\n",
    "* An algorithm is said to be in place if it does not require extra memory, except a constant amount of memory units.\n",
    "* The θ notation can be used to describe the asymptotic space complexity as well.\n",
    "\n",
    "The word asymptotic means we are looking at very large values of N."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
