{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c580fd78",
   "metadata": {},
   "source": [
    "## Integer Operations and Threads\n",
    "Even simple integer operations like increament(++) involve multiple instructions like fetching the value from memory, increamenting the value in the processor core's register and pushing the new value to cache and main memory. Hence a thread can be interrupted inbetween a single integer operation, therefore we should lock the shared integers and operations on them.\n",
    "There is another way, we can tell the compiler that we want this integer variable to be atomic, then the compiler will generate special instructions to disable pre-fetch of the variable and flush the store buffer immediately after doing the operation. This will result in a single interger operation that cannot be interrupted by other threads. This also means the single operation will take longer as we have disabled the optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d04e7",
   "metadata": {},
   "source": [
    "## Atomic Types\n",
    "When we make a variable a atomic type all operations on it will be atomic, other threads will not be able to interleave during that operation. C++ defines an atomic template, the template parameter is the type of the object atomic\\<int\\> x = 0;. Atomic variables must always be initialized. The type parameter must be trivially copyable, which means a built in type or a compound type where all the members are built in types. Normally integer types and pointers are made atomic. For more complex types compilers are allowed to replace them with locks, to avoid this make a pointer of the complex type atomic. We can assign to and from an atomic object in an atomic operation, threads could interleave between two atomic operations.\n",
    "```\n",
    "std::atomic<int> counter = 0;\n",
    "\n",
    "void task()\n",
    "{\n",
    "    for(int i = 0; i < 100'000; ++i)\n",
    "    {\n",
    "        ++counter;\n",
    "    }\n",
    "}\n",
    "\n",
    "void main()\n",
    "{\n",
    "    std::vector<std::thread> tasks;\n",
    "    \n",
    "    for(int i = 0; i < 10; i++)\n",
    "    {\n",
    "        tasks.push_back(std::thread(task));\n",
    "    }\n",
    "    \n",
    "    for(auto &thr : tasks)\n",
    "    {\n",
    "        thr.join();\n",
    "    }\n",
    "}\n",
    "```\n",
    "The volatile keyword has no impact on threading. In C++ if we make a variable volatile it means its value can change at anytime, compiler optimizations which are based on value not being modified from software are removed. Typically used when accessing hardward, for example we could have a network card mapped to a certain memory location, if reads to this location are optimized as the processor is not updating to this memory location(network card is), we will have old data, volatile keyword is used to remove this optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9444e",
   "metadata": {},
   "source": [
    "## Atomic Operations\n",
    "* store() - Atomically replace the object's value with its argument.\n",
    "* load() - Atomically returns the object's value.\n",
    "* operator =() - Assignment operator is same as store.\n",
    "* operator T() - Return operator is same as load.\n",
    "* exchange() - Atomically replaces the object's value with its argument and returns the previous value.\n",
    "* Atomic pointers also support pointer arithmetic operations - increament/decrement operations(++, --), compound increament/decrement operations(+=, -=).\n",
    "* Atomic interger variables support atomic bitwise logical operators(&, | and ^) in addition to the increament/decrement operations.\n",
    "\n",
    "There is also a std::atomic_flag class that can be used instead of std::atomic\\<bool\\>. std::atomic_flag has less overhead and faster. It has only 3 operations, clear()(sets flag to false), test_and_set()(sets flag to true and returns the previous value) and operator =(assignment operator). It must be initialized to false atomic_flag lock=ATOMIC_FLAG_INIT(C++ predefined symbol);\n",
    "\n",
    "The function test_and_set() sets the flag to true and returns the previous value, we can use that for implementing a spin lock. A spin lock is an alternative to using a mutex or condition variable, it is essentially an infinite loop spinning until a condition becomes true. Each thread calls test_and_set() in a loop. If it returns true, some other thread has set the flag and is in critical section, so iterate again. If it returns false, this thread has set the flag, exit the loop and proceed into the critical section. After the critical section set the flag to false.\n",
    "```\n",
    "std::atomic_flag flag = ATOMIC_FLAG_INIT;\n",
    "\n",
    "void task(int n)\n",
    "{\n",
    "    //Loop until we can set the flag\n",
    "    while(flag.test_and_set())\n",
    "    {\n",
    "    }\n",
    "    \n",
    "    //Critical section\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "    std::cout << \"I'm a task with argument \" << n << std::endl;\n",
    "    \n",
    "    //Clear the flag\n",
    "    flag.clear();\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::vector<std::thread> threads;\n",
    "    \n",
    "    for(int i = 0; i < 10; i++)\n",
    "    {\n",
    "        threads.push_back(std::thread(task, i));\n",
    "    }\n",
    "    \n",
    "    for(auto &thr : threads)\n",
    "    {\n",
    "        thr.join();\n",
    "    }\n",
    "}\n",
    "```\n",
    "The spin thread remains active(is not blocked like mutex). Spin lock can continue immediately when it gets the lock, with mutex the thread will need to wait till it is woken up by the schedular. But it very processor-intensive(looping), so only suitable when spinning will be very less(very low contention). Usually used only in operating systems and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1cedcc",
   "metadata": {},
   "source": [
    "## Lock-free Programming\n",
    "In lock-free programming we still have threads executing critical sections concurrently, but we try to remove data races without using locking facilities. There are a number of drawbacks to using locks\n",
    "* Race conditions can be caused by forgetting to lock, or using the wrong mutex.\n",
    "* Locking mutexes is not composable, if we lock one mutex and unlock another mutex without unlocking the first mutex then we have a risk of dead locking.\n",
    "* High overhead and time consuming.\n",
    "* Lack of scalability caused by coarse-grained locking.\n",
    "* Increased overhead caused by fine-grained locking.\n",
    "\n",
    "For these reasons is some systems which are time critical like real time systems we try to use lock-free programming. But it is very difficult to write lock-free code that is both efficient and has no data races. For these reasons it is only tried in cases where performance is critical.  \n",
    "When doing lock free programming, shared data may have different values in different threads, the value of the shared variable may change between an if statement and its body. We use a transactional model for lock-free programming, which is described by the acronym ACID.\n",
    "* Atomic : A transaction either completes successfully(commit), or it fails and leaves everything as it was(rollback).\n",
    "* Consistent : The shared data goes from one consistent state to another. As seen by other users, the shared data is never in an inconsistent state.\n",
    "* Isolated : Two transactions can never work on the same data simultaneously.\n",
    "* Durable : Once a transaction is committed, it will not be lost untill the next transaction is committed.\n",
    "\n",
    "The only way to write lock-free programs is to use atomic instructions. These follow all the 'ACID' semantics. We also need to think carefully about the thread interactions.  \n",
    "Below is a implementation of a simple lock-free queue. It can be accessed by only 2 threads, a producer thread inserts elements into it and a consumer thread that removes elements from it. The code is designed in such a way that the two threads always work on different parts of the queue. The queue uses 2 pointers(iterators), head and tail. The consumer thread does not modify the queue, it removes an element by increamenting the head pointer. Producer inserts elements, increments tails pointer and erases the elements removed by the consumer. This means only the producer thread can modify the queue and the 2 threads can never overlap.\n",
    "```\n",
    "template <typename T>\n",
    "class lock_free_queue\n",
    "{\n",
    "public:\n",
    "    lock_free_queue()\n",
    "    {\n",
    "        m_list.push_back(T());     //Create a dummy element, this will help head and tail not to overlap\n",
    "        m_head = list.begin();\n",
    "        m_tail = list.end();\n",
    "    }\n",
    "    \n",
    "    bool consume(T &t)\n",
    "    {\n",
    "        auto first = m_head;\n",
    "        ++first;\n",
    "        if(first != m_tail)\n",
    "        {\n",
    "            m_head = first;\n",
    "            t = *m_head;\n",
    "            return true;\n",
    "        }\n",
    "        return false;\n",
    "    }\n",
    "    \n",
    "    void produce(const T& t)\n",
    "    {\n",
    "        m_list.push_back(t);\n",
    "        m_tail = m_list.end();\n",
    "        m_list.erase(list.begin(), m_head);    //Erase the elements which the consumer thread has marked for removal \n",
    "    }\n",
    "    \n",
    "private:\n",
    "    std::list<T> m_list;\n",
    "    std::list<T>::iterator m_head, m_tail;\n",
    "};\n",
    "\n",
    "int main()\n",
    "{\n",
    "    lock_free_queue<int> lfq;\n",
    "    std::list<std::thread> threads;\n",
    "    int j = 1;\n",
    "    \n",
    "    for(int i = 0; i < 10; ++i)\n",
    "    {\n",
    "        std::thread produce(&lock_free_queue<int>::produce, &lfq, std::ref(i));\n",
    "        threads.push_back(produce);\n",
    "        std::thread consume(&lock_free_queue<int>::consume, &lfq, std::ref(j));\n",
    "        threads.push_back(consume);\n",
    "    }\n",
    "    \n",
    "    for(std::thread &thr: threads)\n",
    "    {\n",
    "        thr.join();\n",
    "    }\n",
    "}\n",
    "```\n",
    "Still this will not give the desired results, even though the list is modified by only the producer thread,shared variables m_head and m_tail are used by both threads at the same time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
