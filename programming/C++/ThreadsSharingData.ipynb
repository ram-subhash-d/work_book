{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e4a3f4",
   "metadata": {},
   "source": [
    "## Critical Section\n",
    "A region of code that must be executed by only one thread at a time, usually when accessing a shared resource like shared data, network connection or hardware device. Only one thread can enter the critical section at a time, all other threads are locked out. When this thread leaves the critical section, one of the other threads can now enter it. This is called the locking protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f5b73",
   "metadata": {},
   "source": [
    "## Mutex\n",
    "Mutex is a mutual exclusion object, used to implement locking protocol. Mutex has two states 'locked' and 'unlocked'. If the mutex is unlocked, a thread can enter the critical section. If the mutex is locked, no thread can enter until it becomes unlocked. A thread locks the mutex when it enters the critical section. A thread unlocks the mutex when it leaves the critical section. These rules ensure that only one thread can be in the mutex at a given time. Unlocking a mutex also pushes any changes to the shared object/data, so that the new value is available for the other threads.  \n",
    "C++ standard library provides std::mutex class for this, we can use objects of this class to syncronize threads. The mutex object should be visible to all the thread functions that need syncronization.\n",
    "```\n",
    "std::mutex task_mutex;\n",
    "\n",
    "void print(std::string str)\n",
    "{\n",
    "    for(int i = 0; i < 5; i++)\n",
    "    {\n",
    "        //Lock the mutex before the critical section\n",
    "        task_mutex.lock()\n",
    "        \n",
    "        std::cout << str[0] << str[1] << str[2] << std::endl;\n",
    "        \n",
    "        //Unlock the mutex after the critical section\n",
    "        task_mutex.unlock();\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr1(print, \"abc\");\n",
    "    std::thread thr2(print, \"def\");\n",
    "    std::thread thr3(print, \"xyz\");\n",
    "    \n",
    "    thr1.join();\n",
    "    thr2.join();\n",
    "    thr3.join();\n",
    "}\n",
    "```\n",
    "With the mutex the output is not scrambled. lock() is blocking call, thread gets blocked until it gets the mutex. There is also a try_lock() method which returns immediately, returns true if it locked the mutex else false, main use case is to be able to write a loop till the thread gets the mutex and do something else when it does not get the mutex before trying again.\n",
    "```\n",
    "//Keep trying to get the lock\n",
    "while(!task_mutex.try_lock())\n",
    "{\n",
    "    \n",
    "    //Could not get the mutex, try later\n",
    "    std::this_thread::sleep_for(100ms);\n",
    "}\n",
    "\n",
    "//Finally got the mutex, can execute the critical section\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60010e1c",
   "metadata": {},
   "source": [
    "## Internally Synchronized Class\n",
    "C++ STL containers need to be externally syncronized, by locking a mutex before calling a member function. They are not internally syncronised(thread safe). We can provide internal syncronization for our own types, with std::mutex as a data member and locking/unlocking when accessing the class's data. Here the class is taking the resposibility to prevent the data race not the caller of the class.\n",
    "```\n",
    "class sync_vector\n",
    "{\n",
    "public:\n",
    "    void push_back(const int& i)\n",
    "    {\n",
    "        m_mut.lock();\n",
    "        m_vec.push(i);\n",
    "        m_mut.unlock();\n",
    "    }\n",
    "    \n",
    "private:\n",
    "    std::mutex m_mut;\n",
    "    std::vector<int> m_vec;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c6ef5",
   "metadata": {},
   "source": [
    "## Lock Gaurd\n",
    "If an exception is thrown in a critical section, then the mutex will be left locked.\n",
    "```\n",
    "try\n",
    "{\n",
    "    task_mutex.lock();\n",
    "    \n",
    "    //Critical section throws an exception\n",
    "    \n",
    "    task_mutex.unlock(); //Never gets called\n",
    "}\n",
    "catch(std::exception &e)\n",
    "{\n",
    "}\n",
    "```\n",
    "That's why we don't use the mutex class directly. C++ provides wrapper classes on mutex. These classes use the RAII idiom to manage resources, in this case the resource is the std::mutex. We create the wrapper class on the stack, when the object goes out of scope, destructor is called and the mutex is unlocked, even when an exception is thrown.  \n",
    "The first one is the std::lock_gaurd, very basic wrapper with only a constructor and a destructor. std::lock_guard is template class, templete parameter is the type of the mutex. That is because C++ has different types of mutexes.\n",
    "```\n",
    "try\n",
    "{\n",
    "    std::lock_guard<std::mutex> lck_guard(task_mutex);\n",
    "    \n",
    "    //Critical section that might throw an exception\n",
    "    \n",
    "    //When lck_guard goes out of scope, task_mutex is unlocked \n",
    "}\n",
    "catch(std::exception &e)\n",
    "{\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2619419",
   "metadata": {},
   "source": [
    "## Unique Lock\n",
    "std::unique_lock has the same basic features as std::lock_guard, plus a unlock member function. We can explicitly call unlock no need to wait for the destructor.\n",
    "```\n",
    "try\n",
    "{\n",
    "    std::unique_lock<std::mutex> uniq_lock(task_mutex);\n",
    "    \n",
    "    //Critical section that might throw an exception\n",
    "    \n",
    "    uniq_lock.unlock();\n",
    "    \n",
    "    //do something which is not critical\n",
    "}\n",
    "catch(std::exception &e)\n",
    "{\n",
    "}\n",
    "```\n",
    "std::unique_lock constructor gives more options. If the second argument is std::try_to_lock, then mutex's try_lock() will be used, so the constructor will immediately return, it has owns_lock() member to check if mutex is locked. If we pass std::defer_lock as the second argument, then the constructor will not lock the mutex, we have to lock() explicitly. If we pass std::adopt_lock as the second argument, the constructor will assume that the mutex is already locked, helps in situations where mutex can be locked twice. std::unique_lock is a move only object like the std::unique_ptr.  \n",
    "For a basic case we have to use a lock_gaurd as it is small and fast, if we need any of the above functionality we can use the unique_lock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf164241",
   "metadata": {},
   "source": [
    "## Timed Mutex\n",
    "std::timed_mutex is similar to std::mutex, but with extra member functions. try_lock_for(), keep trying to lock the mutex for a specified duration. try_lock_until(), keep trying to lock the mutex until a specified time. These return true if they get the mutex else false.\n",
    "```\n",
    "std::timed_mutex the_mutex;\n",
    "\n",
    "void task1()\n",
    "{\n",
    "    the_mutex.lock();\n",
    "    std::this_thread::sleep_for(5s);\n",
    "    the_mutex.unlock();\n",
    "}\n",
    "\n",
    "void task2()\n",
    "{\n",
    "    std::this_thread::sleep_for(500ms);\n",
    "    \n",
    "    //Try for 1 second to lock the mutex\n",
    "    while(!the_mutex.try_lock_for(1s))\n",
    "    {\n",
    "        //Try again on the next iteration\n",
    "    }\n",
    "    \n",
    "    //The mutex is locked now, execute the critical section\n",
    "    \n",
    "    the_mutex.unlock();\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr1(task1);\n",
    "    std::thread thr2(task2);\n",
    "    \n",
    "    thr1.join();\n",
    "    thr2.join();\n",
    "}\n",
    "```\n",
    "Like the normal std::mutex we can use any of the wrapper class on std::timed_mutex, hence wrapper classes like std::lock_guard and std::unique_lock are template parameterised with mutex type. std::unique_lock also has try_lock_for() and try_lock_until() methods, but you cannot use these methods if the template parameter is std::mutex, you get a compilation error.\n",
    "```\n",
    "std::timed_mutex the_mutex;\n",
    "\n",
    "void task1()\n",
    "{\n",
    "    //Use lock_guard, no need to explicitly call unlock\n",
    "    std::lock_guard<std::timed_mutex> lck_guard(the_mutex);\n",
    "    std::this_thread::sleep_for(5s);\n",
    "}\n",
    "\n",
    "void task2()\n",
    "{\n",
    "    std::this_thread::sleep_for(500ms);\n",
    "    \n",
    "    //std::defer_lock, will not lock the mutex in the constructor\n",
    "    std::unique_lock<std::timed_mutex> uniq_lck(the_mutex, std::defer_lock);\n",
    "    \n",
    "    //Try for 1 second to lock the mutex\n",
    "    while(!uniq_lck.try_lock_for(1s))\n",
    "    {\n",
    "        //Try again on the next iteration\n",
    "    }\n",
    "    \n",
    "    //The mutex is locked now, execute the critical section\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr1(task1);\n",
    "    std::thread thr2(task2);\n",
    "    \n",
    "    thr1.join();\n",
    "    thr2.join();\n",
    "}\n",
    "```\n",
    "try_lock_for() and try_lock_until() may return later than requested due to thread scheduling delays.  \n",
    "lock() cannot be called twice by the same thread before unlock(), this behaviour is undefined. C++ also has std::recursive_mutex, whose lock() can be called repeatedly by the same thread without calling unlock(), for each lock() call there must eventually be an unlock() call, else other threads cannot access the critical section. Using std::recursive_mutex is normally a sign of bad design. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5475c",
   "metadata": {},
   "source": [
    "## Multiple Reader, Single Writer\n",
    "In cases like financial data feed for infrequently traded stocks, audio/vedio buffers in multimedia players, there will be many clients accessing the data(read) but only a occasional update(write). Here there is a high probability that many readers want concurrent access, in which case locking is not required. Other cases where atleast one writer is asking for access is low probability and need locking. With std::mutex all threads are syncronised even when not required(all readers case), loss of concurrency reduces performance.\n",
    "```\n",
    "std::mutex mut;\n",
    "//Shared variable\n",
    "int x = 0;\n",
    "\n",
    "void write()\n",
    "{\n",
    "    std::lock_guard<std::mutex> lck_guard(mut);\n",
    "    ++x;\n",
    "}\n",
    "\n",
    "void read()\n",
    "{\n",
    "    std::lock_guard<std::mutex> lck_guard(mut);\n",
    "    std::cout << x << std::endl;\n",
    "    std::this_thread::sleep_for(100ms);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::vector<std::thread> threads;\n",
    "    for(int i = 0; i < 20; i++)\n",
    "    {\n",
    "        //Thread is moved into the vector\n",
    "        threads.push_back(std::thread(read));\n",
    "    }\n",
    "    \n",
    "    threads.push_back(std::thread(write));\n",
    "    threads.push_back(std::thread(write));\n",
    "    \n",
    "    for(int i = 0; i < 20; i++)\n",
    "    {\n",
    "        //Thread is moved into the vector\n",
    "        threads.push_back(std::thread(read));\n",
    "    }\n",
    "    \n",
    "    for(auto& thr : threads)\n",
    "    {\n",
    "        thr.join();\n",
    "    }\n",
    "}\n",
    "```\n",
    "To solve this problem we need selective locking, lock only when one of the threads is writing. These are called read-write lock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f7d58",
   "metadata": {},
   "source": [
    "## Shared Mutex\n",
    "C++ implemented read-write lock with std::shared_mutex. It can be locked in 2 ways. Exclusive lock, no other thread may acquire a lock(like lock on other mutex objects).  Shared lock, other threads may acquire a shared lock and execute critical sections concurrently. To get a exclusive lock we have to use std::lock_guard\\<std::shared_mutex\\> or std::unique_lock\\<std::shared_mutex\\>. To get shared lock we have to use std::shared_lock\\<std::shared_mutex\\>. We can get a exclusive lock only if no other thread is having a shared or exclusive lock, else it has to wait for all other threads to unlock. We can get a shared lock if no other thread is having a exclusive lock.\n",
    "```\n",
    "std::shared_mutex shmut;\n",
    "//Shared variable\n",
    "int x = 0;\n",
    "\n",
    "void write()\n",
    "{\n",
    "    std::lock_guard<std::shared_mutex> lck_guard(shmut);\n",
    "    ++x;\n",
    "}\n",
    "\n",
    "void read()\n",
    "{\n",
    "    std::shared_lock<std::shared_mutex> shared_lck(shmut);\n",
    "    std::cout << x << std::endl;\n",
    "    std::this_thread::sleep_for(100ms);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::vector<std::thread> threads;\n",
    "    for(int i = 0; i < 20; i++)\n",
    "    {\n",
    "        //Thread is moved into the vector\n",
    "        threads.push_back(std::thread(read));\n",
    "    }\n",
    "    \n",
    "    threads.push_back(std::thread(write));\n",
    "    threads.push_back(std::thread(write));\n",
    "    \n",
    "    for(int i = 0; i < 20; i++)\n",
    "    {\n",
    "        //Thread is moved into the vector\n",
    "        threads.push_back(std::thread(read));\n",
    "    }\n",
    "    \n",
    "    for(auto& thr : threads)\n",
    "    {\n",
    "        thr.join();\n",
    "    }\n",
    "}\n",
    "```\n",
    "std::shared_mutex also has member functions if you want to work with it directly. Exclusive, lock(), try_lock(), unlock(). Shared, lock_shared(), try_lock_shared(), unlock_shared(). std::shared_mutex uses more memory and is slower than std::mutex, but it is suited for situations there are a lot of read threads and small number of write threads. We get a performance boost with concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ec77f",
   "metadata": {},
   "source": [
    "## Shared Static Data Initialization\n",
    "Shared data can be a global variable, static variable at namespace scope, static class member and static local variable. The first 3 are initialized when the program starts before the main() function is called, no data race as only one thread is running at this point. For the static local variable initialization happens when the function is called during program execution, this may result in 2 or more threads calling the constructor concurrently, thus may result in data race. Before C++ 11 the only way to solve this is to use a mutex, but that would mean locking the mutex every time the program passes through the decleration not just during initialization. This is resolved in C++ 11, local static variable initialization is internally syncronised. This is only for initalization, for subsequent modifications the usual rules of shared data apply, they have to be protected. Below is a C++ singleton implementation before and after C++ 11.\n",
    "```\n",
    "class singleton\n",
    "{\n",
    "public:\n",
    "    //Before C++ 11\n",
    "    static singleton* get_singleton()\n",
    "    {\n",
    "        mut.lock();\n",
    "        if(single == nullptr)\n",
    "        {\n",
    "            single = new singleton();\n",
    "        }\n",
    "        mut.unlock();\n",
    "        return single;\n",
    "    }\n",
    "    \n",
    "    //In C++ 11 we can take advantage of thread-safe initialization of static local variables\n",
    "    //We can also move this function outside the singleton class too\n",
    "    static singleton& get_singleton()\n",
    "    {\n",
    "        static singleton single;\n",
    "        return single;\n",
    "    }\n",
    "    \n",
    "    //Delete copy and move operators here\n",
    "    \n",
    "    //Class functionality here\n",
    "\n",
    "private:\n",
    "    //Private constructor here to make the object singleton\n",
    "    \n",
    "    static singleton* single;\n",
    "    static std::mutex mut;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cd08e",
   "metadata": {},
   "source": [
    "## Thread-local Data\n",
    "Use the thread_local keyword to declare them, then each thread will have a copy of the object. These variables can be global varaibles or data members of a class or local variables in a function. They are always initialized the first time they are used and destroyed when the thread completes execution.\n",
    "```\n",
    "//Thread local random number engine\n",
    "//One varaible for each thread\n",
    "std::thread_local mt19937 mt;\n",
    "\n",
    "void func()\n",
    "{\n",
    "    std::uniform_real_distribution<double> dist(0, 1);\n",
    "    \n",
    "    for(int i = 0; i < 10; i++)\n",
    "    {\n",
    "        std::cout << dist(mt) << \",\";\n",
    "    }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr1(func);\n",
    "    thr1.join();\n",
    "    \n",
    "    std::thread thr2(func);\n",
    "    thr2.join();\n",
    "}\n",
    "\n",
    "```\n",
    "Both threads will generate the same random numbers as they are using seperate engine objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf29715",
   "metadata": {},
   "source": [
    "## Lazy initialization\n",
    "Lazy initialization is another concept that might need handling in multi-threaded code. Lazy initialization is where the varaible is only initialized when it is first used, used for objects that are expensive to construct.\n",
    "```\n",
    "//Lazy initialization(single-threaded)\n",
    "class test\n",
    "{\n",
    "public:\n",
    "    void func() { /*...*/ }\n",
    "};\n",
    "\n",
    "test *ptest = nullptr;    //Variable to be lazily initialized\n",
    "\n",
    "void process()\n",
    "{\n",
    "    if(!ptest)                    //First time variable has been used\n",
    "    {\n",
    "        ptest = new test();       //Initialize it\n",
    "    }\n",
    "    ptest->func();                //Use it\n",
    "}\n",
    "```\n",
    "ptest initialization is not thread safe here, we can use a mutex for the initialization but it is inefficient as mutex gets locked always, not just for the first time when it is needed. We can solve this by using a shared lock. Another way to solve this is to check the variable ptest twice.\n",
    "```\n",
    "//Lazy initialization\n",
    "class test\n",
    "{\n",
    "public:\n",
    "    void func() { /*...*/ }\n",
    "};\n",
    "\n",
    "std::mutex mut;\n",
    "test *ptest = nullptr;            //Variable to be lazily initialized\n",
    "\n",
    "void process()\n",
    "{\n",
    "    if(!ptest)                    //First time variable has been used\n",
    "    {\n",
    "        std::lock_guard lck_guard(mut);\n",
    "        if(!ptest)\n",
    "        {\n",
    "            ptest = new test();       //Initialize it\n",
    "        }\n",
    "    }\n",
    "    ptest->func();                //Use it\n",
    "}\n",
    "```\n",
    "The second check is needed because when one thread has entered the lock, another thread could be interleaved and waiting at the lock statement. But this implementation too could still have a problem in C++, as new is a 3 step operation, construct the required memory, assign the pointer to ptest and initialize the memory. Say one thread is initializing ptest, it got the pointer but the memory is not initialized yet, if another thread comes at this point ptest check will pass, so it calls func() on an uninitialized object. One way to solve this is to use std::call_once, this will guarantee that a given function will be called only once. So only one thread executes it and it cannot be interrupted while the function is executing. std::call_once is thread safe.\n",
    "```\n",
    "//Lazy initialization\n",
    "class test\n",
    "{\n",
    "public:\n",
    "    void func() { /*...*/ }\n",
    "};\n",
    "\n",
    "test *ptest = nullptr;            //Variable to be lazily initialized\n",
    "std::once_flag ptest_flag;\n",
    "\n",
    "void process()\n",
    "{\n",
    "    //Pass a callable object which performs the initialization\n",
    "    std::once_call(ptest_flag, [](){\n",
    "        ptest = new test();\n",
    "        });\n",
    "    ptest->func();                //Use it\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd50d78",
   "metadata": {},
   "source": [
    "## Deadlock\n",
    "A thread is dead locked when it cannot run, normally this happens when two or more threads are waiting on each other.\n",
    "```\n",
    "std::mutex mut1;\n",
    "std::mutex mut2;\n",
    "\n",
    "void func_a()\n",
    "{\n",
    "    std::lock_guard lck_guard1(mut1);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "    std::lock_guard lck_guard2(mut2);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "}\n",
    "\n",
    "void func_b()\n",
    "{\n",
    "    std::lock_guard lck_guard1(mut2);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "    std::lock_guard lck_guard2(mut1);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr_a(func_a);\n",
    "    std::thread thr_b(func_b);\n",
    "    \n",
    "    thr_a.join();\n",
    "    thr_b.join();\n",
    "}\n",
    "```\n",
    "One way to avoid deadlock is for both the threads to try to acquire the locks in the same order. We need better approaches as this might not be feasible in large programs.  \n",
    "One such solution is to lock multiple mutexes in a single operation. C++ has std::scoped_lock for this, it is similar to lock_guard except it can lock more than one mutex at the same time.\n",
    "```\n",
    "std::mutex mut1;\n",
    "std::mutex mut2;\n",
    "\n",
    "void func_a()\n",
    "{\n",
    "    std::scoped_lock scoped_lck(mut1, mut2);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "}\n",
    "\n",
    "void func_b()\n",
    "{\n",
    "    std::scoped_lock scoped_lck(mut1, mut2);\n",
    "    std::this_thread::sleep_for(50ms);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::thread thr_a(func_a);\n",
    "    std::thread thr_b(func_b);\n",
    "    \n",
    "    thr_a.join();\n",
    "    thr_b.join();\n",
    "}\n",
    "```\n",
    "Global std::lock and std::try_lock methods also allow to lock multi locks at the same time.  \n",
    "Sometimes it is not feasible to acquire multiple locks simultaneously, then a common technique is to use ordering, like a thread cannot lock a mutex unless it has locked a mutex with a lower number. This is known as hierarchical mutex.  \n",
    "Some ways to avoid deadlock are, avoid waiting for a thread while holding a lock, avoid nested locks, if you need multiple locks acquire them in a single operation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85a975",
   "metadata": {},
   "source": [
    "## Livelock\n",
    "In livelock too the program cannot make the progress, but the threads are still active and not doing anything useful, stuck in a loop.\n",
    "```\n",
    "std::mutex mut1;\n",
    "std::mutex mut2;\n",
    "\n",
    "void func_a()\n",
    "{\n",
    "    std::this_thread::sleep_for(10ms);\n",
    "    bool locked = false;\n",
    "    \n",
    "    while(!locked)\n",
    "    {\n",
    "        std::lock_guard lck_guard1(mut1);\n",
    "        std::this_thread::sleep_for(2s);\n",
    "        locked = mut2.try_lock();\n",
    "    }\n",
    "    \n",
    "    if(locked)\n",
    "    {\n",
    "        std::cout << \"Thread A has locked both mutexes\" << std::endl;\n",
    "    }\n",
    "}\n",
    "\n",
    "void func_b()\n",
    "{\n",
    "    bool locked = false;\n",
    "    \n",
    "    while(!locked)\n",
    "    {\n",
    "        std::lock_guard lck_guard2(mut2);\n",
    "        std::this_thread::sleep_for(2s);\n",
    "        locked = mut1.try_lock();\n",
    "    }\n",
    "    \n",
    "    if(locked)\n",
    "    {\n",
    "        std::cout << \"Thread B has locked both mutexes\" << std::endl;\n",
    "    }\n",
    "}\n",
    "```\n",
    "To avoid livelock, do the dead lock avoidance in the rignt way as described in the deadlock section, like using std::scoped_lock or std::lock.  \n",
    "Threads can also have priorities, not directly supported by C++. We have to use the native implemetation using std::thread's native_handle() method. A high priority thread will run more ofen, a low priority thread is interrupted more often.  \n",
    "Resource starvation can happen when, a thread cannot get the resources it needs to run(e.g deadlock/livelock), lack of system resources can prevent a thread starting(e.g system memory exhausted) or low priority threads may get starved of processor time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069e5ad",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Always hold the lock for the sortest possible time, else it will have a performance impact. Recomendation for reading shared data is to lock, make a copy of the shared data, unlock and then process the copy. Recomendation for writing shared data is to lock, make a copy of the shared data, unlock and then process the copy, lock again, update the shared data from the copy and then unlock. When making data structures thread safe, do not lock any more elements than necessary or do not make locking too fine-grained, we have to find a middle path. For example if you lock the entire linked list then other threads will be blocked even when accessing unrelated elements. On the other hand if it is too fine-grained like locking individual elements, then operation like insert and delete might have a data race as these operations effect neibouring elements. Locking/unlocking are slow operations, syncronization with semaphores is much faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
