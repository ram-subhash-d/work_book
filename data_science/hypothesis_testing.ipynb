{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765913b9-6844-43eb-9dc0-b4ec18c60d4e",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "Hypothesis testing is an act where we test an assumption or a theoretical value(the hypothesis) about a population parameter. We asess the plausibility of a hypothesis by using sampling data.\n",
    "\n",
    "## Sampling Techniques\n",
    "Sampling is a technique where we pick a subset of data and analyse that instead of the entire population. If the right samples  are picked then the analysis can be a good representation of the entire data set. Sampling enables us to determine a polulation's characteristics by directly observing only a portion of the population. There are two ways to do the sampling, probability sampling and non-probability sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3753667-066c-4d32-9f51-ee1f27a95a54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Probability Sampling\n",
    "Probability sampling is where, every element of the population has an equal chance of being selected. Probability sampling gives us the best chance to create a sample that is the best representative of the population. Below are the types of probility sampling.\n",
    "\n",
    "**Simple Random Sampling:** Here, every individual is chosen entirely by chance and each member of the population has an equal chance of being selected. A lottery system is used to determine which unints are to be selected. It is applicable when population is small, homogeneous and redily available. It comes with a caveat, it may not select enough individuals with our characteristics of interest.\n",
    "\n",
    "**Systematic Sampling:** In this type of sampling, the first individual is selected randomly from the first ‘sampling interval’(i.e from 1 to population size/no. of samples), and others are selected using a fixed ‘sampling interval’. It relies on arranging the target population according to some ordering scheme and then selecting elements at regular intervals through that ordered list.\n",
    "\n",
    "**Stratified Sampling:** In this type of sampling, we divide the population into subgroups , called strata based on different traits like gender, category, etc. then we select the samples from these subgroups proportionate to the size of the subgroup. We use this type of sampling when we want representation from all the subgroups of the population. However, stratified sampling requires proper knowledge of the characteristics of the population.\n",
    "\n",
    "**Cluster Sampling:** In a clustered sample, we use the subgroups of the population as the sampling unit rather than individuals. The population is divided into subgroups, known as clusters, and a whole cluster is randomly selected to be included in the study. Clusters are homogeneous units, usally based on geographical contiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562df4d-49e8-4abe-8dc6-eab3f5bec605",
   "metadata": {},
   "source": [
    "## Non-Probability Sampling\n",
    "Non-probability sampling is where, all elements do not have an equal chance of being selected. There is a pre determined basis for selection, based on the situation. Which means, there is a significant risk of ending up with a non-representative sample of the population.\n",
    "\n",
    "**Convenience Sampling:** Individuals are selected based on their availability and willingness to take part. In is prone to significant bias.\n",
    "\n",
    "**Quota Sampling:** In this type of sampling, we choose items based on predetermined characteristics of the population. Sampling is done based on reservation.\n",
    "\n",
    "**Judgment Sampling:** Here the experts judge and choose the samples. It is prone to bias by the experts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04cbda-05c8-4db3-938e-5548a690c0dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Null Hypothesis(H0)\n",
    "If there is no signicant difference between hypothesis and the result of the hypothesis testing, then we say that the null hypothesis holds true. Meaning we failed to reject null hypothesis. Generally the signicance level(alpha:α) is considered to be 1% or 5%, it is dependent on confidence in data and default is 5%. A significance level of 1% means we have 99% confidence in our data. If we take significane level as 1%, then if the difference between the hypothesis and result of the hypothesis testing is less than 1% then null hypothesis holds true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823280d0-64eb-4574-b252-1f8417e88129",
   "metadata": {},
   "source": [
    "## Alternate Hypothesis(H1 or Ha)\n",
    "If there is a signicant difference between hypothesis and the result of the hypothesis testing, then we say that the alternate hypothesis holds true. Meaning we can reject null hypothesis. if we take significane level as 1%, then if the difference between the hypothesis and result of the hypothesis testing is greater than 1% then we reject null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265da6dd-4b09-4ec5-94d5-d8c397026ff6",
   "metadata": {},
   "source": [
    "## P-value\n",
    "P-value has the inverse effect of significance level. A significance level of 5% means a p-value of 0.05. So if the p-value is less than 0.05 then we reject null hypothesis else we accept null hypothesis.\\\n",
    "P-value < 0.05 - Ha\\\n",
    "P-value > 0.05 - H0\\\n",
    "P-value = 0.05 - Ha/H0 depending on data and analysis\\\n",
    "P-value is the measure of difference between hypothesis and the result of the hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f2b90-ad27-4f95-bf9d-7c50c1e76721",
   "metadata": {},
   "source": [
    "## Z-Test\n",
    "Formula : Z = (x - μ)/(σ/√n) , x - sample mean,  μ - population mean, σ - standard deviation(population), n - number of records(sample).\\\n",
    "We can apply z-test only when our data follows normally distributed curve and the number of records are greater than 30. First we calculate the Z value using the above formula, then we can get the corresponding p-value for the calculated z-value from the z-table. In the z-table on the y axis we look for sign, integral and the first decimal point of the p-value, and the second decimal point on the x axis, the intersecting value is the p-value. If p-value is greater than 0.05 we accept the null hypothesis else reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe89ad6-574a-4786-bc28-7256613d8ff2",
   "metadata": {},
   "source": [
    "## T-Test\n",
    "Formula: Tn-1 = (x̄ - μ0)/(s/√n), x̄ - sample mean, μ0 - population mean, s - standard deviation(sample), n - number of records(sample).\n",
    "If the sample size is less than 30 then we can go for t-test. If the number of records are less than 30 data follows t distribution.\n",
    "Here Tn-1 is the value from t distribution with n-1 degree's of freedom. For a sample of size n, the degree of freedom will be n - 1. That is when doing the calculation we will have freedom to select a sample n - 1 times, the last time we dont have the freedom, we have to pick the remaining one. Another case where we use t-test is when we dont know the standard deviation of the population. The result of the formula calculation, Tn-1 is called the 'test statistic'. To do the t-test we need two parameters test statistic(from formula) and critical distance. Critical distance can be found from the t-table. In the t-table on the y-axis look for the degrees of freedom and the signicance level on the x-axis, the intersecting value is the critical distance. Then we compare test statistic and critical distance. if test statistic is greater than critical distance then reject null hypothesis else accept it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c86747-5447-4802-bf9e-4b1e16a423ce",
   "metadata": {},
   "source": [
    "## Anova(Analysis of Variance/F-test)\n",
    "Both z-test and t-test are used when we have two groups(ex: population and one sample) to compare, when there are more than two groups then we go for anova. Another case where we choose anova is when variance is an important factor of the analysis being done. It tells what is the co relation between the variables.\\\n",
    "Formula: Fisrt calculate total variance, Total variance(SST) = summation(variance between the groups(SSC) + variance within the groups(SSE)). To calculate SSE, calculate the mean of each group and then variances within each group and add them all up. To calculate the SSC, calculate the grand mean of all the groups, then the variances between grand mean and individual group means(sqrt(GM - M)), then SSC = Summation(number of observations in each group * sqrt(GM - M)).\n",
    "Once we have the SST the next step is to find F-Ratio. F-Ratio = mean square column(MSC)/mean squre error(MSE), MSC = SSC/degrees of freedom(k -1); k is number of groups, MSE = SSE/degrees of freedom(n - k); n is total number of samples in all groups. F-Ratio is called as test statistic. Then from the F-table we have to find the critical disatnce, there will be one table for each significance level. In the f-table on the x-axis we have k-1 and n-k on the y-axis, the intersecting value is the critical distance. Then we compare test statistic and critical distance. if test statistic is greater than critical distance then reject null hypothesis else accept it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4b33d-8df6-44c2-a52e-7289b5533607",
   "metadata": {},
   "source": [
    "## Chi-Square\n",
    "It is test for independence between a categorical variable. Used when the analysis involves only multiple categorical variables.For example if we have to check the independence between males and females depending on the number of cats, dogs and birds they buy. Here we compare the hypothesis testing value with the bench mark value(calculated/expected).\\\n",
    "Formula: sqr(Observed value(sample data) - Calculated value)/Calculated value. To do the chi-square test we should always have the expected/calculated values. If we don't have the calculated values we have 2 options, one is to take 50% of observed values(i.e column total/number of rows) and the second is to calculate with (row total * column total)/(over all total) of the sample data. Do this for all the values in the matrix of sample data. Then for every value calculate the chi-square value by applying the above formula. Then add them all up to get the test statistic.Then from the chi-square-table we have to find the critical disatnce. In the chi-sqaure-table on the x-axis we have significance level and degress of freedom on the y-axis, here degrees of freedom is (row -1) * (columns - 1), the intersecting value is the critical distance. Then we compare test statistic and critical distance. if test statistic is greater than critical distance then reject null hypothesis else accept it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
